{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '20news-bydate-train'\n",
    "test_dir = '20news-bydate-test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_train_dirs = []\n",
    "list_test_dirs = []\n",
    "\n",
    "for file_dir in glob.glob(train_dir+'/*'):\n",
    "    list_train_dirs.append(file_dir)\n",
    "for file_dir in glob.glob(test_dir+'/*'):\n",
    "    list_test_dirs.append(file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(list_dirs):\n",
    "    data = []\n",
    "    for group_id, newsgroup_dir in enumerate(list_dirs):\n",
    "        for text_dir in glob.glob(newsgroup_dir+'/*'):\n",
    "            with open(text_dir) as f:\n",
    "                text = f.read().lower()\n",
    "                \n",
    "                words = [stemmer.stem(word)\n",
    "                        for word in re.split('\\W+', text)\n",
    "                        if word not in stop_words]\n",
    "                \n",
    "                content = ' '.join(words)\n",
    "                assert len(content.splitlines()) == 1\n",
    "                data.append(str(group_id)+'<fff>'+\n",
    "                           text_dir[-5:]+'<fff>'+content)\n",
    "                \n",
    "    return data\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemmer = PorterStemmer()\n",
    "# stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_data(list_train_dirs)\n",
    "test_data = get_data(list_test_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = train_data + test_data\n",
    "\n",
    "with open('data_processed/20news-train-processed.txt', 'w') as f:\n",
    "    f.write('\\n'.join(train_data))\n",
    "    \n",
    "with open('data_processed/20news-test-processed.txt', 'w') as f:\n",
    "    f.write('\\n'.join(test_data))\n",
    "    \n",
    "with open('data_processed/20news-full-processed.txt', 'w') as f:\n",
    "    f.write('\\n'.join(full_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "full_data = []\n",
    "\n",
    "with open('data_processed/20news-train-processed.txt') as f:\n",
    "    train_data = f.readlines()\n",
    "    \n",
    "with open('data_processed/20news-test-processed.txt') as f:\n",
    "    test_data = f.readlines()\n",
    "    \n",
    "with open('data_processed/20news-full-processed.txt') as f:\n",
    "    full_data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vocabulary(data_path):\n",
    "    def compute_idf(df, corpus_size):\n",
    "        assert df > 0\n",
    "        return np.log10(corpus_size * 1./df)\n",
    "    \n",
    "    with open(data_path) as f:\n",
    "        lines = f.read().splitlines()\n",
    "    doc_count = defaultdict(int)\n",
    "    corpus_size = len(lines)\n",
    "    \n",
    "    for line in lines:\n",
    "        features = line.split('<fff>')\n",
    "        text = features[-1]\n",
    "        words = list(set(text.split()))\n",
    "        for word in words:\n",
    "            doc_count[word] += 1\n",
    "            \n",
    "    words_idfs = [(word, compute_idf(document_freq, corpus_size))\n",
    "            for word, document_freq in zip(doc_count.keys(), doc_count.values())\n",
    "            if document_freq > 10 and not word.isdigit()]\n",
    "\n",
    "    words_idfs.sort(key=lambda idf: -idf[1])\n",
    "    print('Vocabulary size:', len(words_idfs))\n",
    "\n",
    "    with open('data_processed/words_idfs.txt', 'w') as f:\n",
    "        f.write('\\n'.join([word + '<fff>'+str(idf) for word, idf in words_idfs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 14212\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data_processed/20news-full-processed.txt'\n",
    "generate_vocabulary(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_idf(data_path):\n",
    "    with open('data_processed/words_idfs.txt') as f:\n",
    "        words_idfs = [(line.split('<fff>')[0], float(line.split('<fff>')[1]))\n",
    "                     for line in f.read().splitlines()]\n",
    "        \n",
    "        word_IDs = dict([(word, index)\n",
    "                        for index, (word, idf) in enumerate(words_idfs)])\n",
    "        idfs = dict(words_idfs)\n",
    "        \n",
    "    with open(data_path) as f:\n",
    "        documents = [\n",
    "            (int(line.split('<fff>')[0]),\n",
    "            line.split('<fff>')[1],\n",
    "            line.split('<fff>')[2])\n",
    "            for line in f.read().splitlines()]\n",
    "\n",
    "    data_tf_idf = []\n",
    "    for document in documents:\n",
    "        label, doc_id, text = document\n",
    "        words = [word for word in text.split() if word in idfs]\n",
    "        word_set = list(set(words))\n",
    "        max_term_freq = max([words.count(word) for word in word_set])\n",
    "        words_tfidfs = []\n",
    "        sum_squares = 0.0\n",
    "        for word in word_set:\n",
    "            term_freq = words.count(word)\n",
    "            tf_idf_value = term_freq * 1. / max_term_freq * idfs[word]\n",
    "            words_tfidfs.append((word_IDs[word], tf_idf_value))\n",
    "            sum_squares += tf_idf_value ** 2\n",
    "            \n",
    "        words_tfidfs_normalized = [str(index) + ':'\n",
    "                                  + str(tf_idf_value / np.sqrt(sum_squares))\n",
    "                                  for index, tf_idf_value in words_tfidfs]\n",
    "        \n",
    "        sparse_rep = ' '.join(words_tfidfs_normalized)\n",
    "        data_tf_idf.append((label, doc_id, sparse_rep))\n",
    "           \n",
    "    with open('data_processed/data_tf_idf.txt', 'w') as f:\n",
    "        f.write('\\n'.join([str(label)+'<fff>'+str(doc_id)+'<fff>'+sparse_rep for label, doc_id, sparse_rep in data_tf_idf]))   \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '49960', 'mathew mathew manti co uk subject alt atheism faq atheist resourc summari book address music anyth relat atheism keyword faq atheism book music fiction address contact expir thu 29 apr 1993 11 57 19 gmt distribut world organ manti consult cambridg uk supersed 19930301143317 manti co uk line 290 archiv name atheism resourc alt atheism archiv name resourc last modifi 11 decemb 1992 version 1 0 atheist resourc address atheist organ usa freedom religion foundat darwin fish bumper sticker assort atheist paraphernalia avail freedom religion foundat us write ffrf p box 750 madison wi 53701 telephon 608 256 8900 evolut design evolut design sell darwin fish fish symbol like one christian stick car feet word darwin written insid delux mould 3d plastic fish 4 95 postpaid us write evolut design 7119 laurel canyon 4 north hollywood ca 91605 peopl san francisco bay area get darwin fish lynn gold tri mail figmo netcom com net peopl go lynn directli price 4 95 per fish american atheist press aap publish variou atheist book critiqu bibl list biblic contradict one book bibl handbook w p ball g w foot american atheist press 372 pp isbn 0 910309 26 4 2nd edit 1986 bibl contradict absurd atroc immor contain ball foot bibl contradict aap base king jame version bibl write american atheist press p box 140195 austin tx 78714 0195 7215 cameron road austin tx 78752 2973 telephon 512 458 1244 fax 512 467 9525 prometheu book sell book includ haught holi horror see write 700 east amherst street buffalo new york 14215 telephon 716 837 2475 altern address may newer older prometheu book 59 glenn drive buffalo ny 14228 2197 african american human organ promot black secular human uncov histori black freethought publish quarterli newslett aah examin write norm r allen jr african american human p box 664 buffalo ny 14226 unit kingdom rationalist press associ nation secular societi 88 islington high street 702 holloway road london n1 8ew london n19 3nl 071 226 7251 071 272 1266 british humanist associ south place ethic societi 14 lamb conduit passag conway hall london wc1r 4rh red lion squar 071 430 0908 london wc1r 4rl fax 071 430 1271 071 831 7723 nation secular societi publish freethink monthli magazin found 1881 germani ibka e v international bund der konfessionslosen und atheisten postfach 880 1000 berlin 41 germani ibka publish journal miz materialien und informationen zur zeit politisch journal der konfessionslosesn und atheisten hrsg ibka e v miz vertrieb postfach 880 1000 berlin 41 germani atheist book write ibdk international b ucherdienst der konfessionslosen postfach 3005 3000 hannov 1 germani telephon 0511 211216 book fiction thoma disch santa clau compromis short stori ultim proof santa exist charact event fictiti similar live dead god uh well walter miller jr canticl leibowitz one gem post atom doomsday novel monk spent live copi blueprint saint leibowitz fill sheet paper ink leav white line letter edgar pangborn davi post atom doomsday novel set cleric state church exampl forbid anyon produc describ use substanc contain atom philip k dick philip k dick dick wrote mani philosoph thought provok short stori novel stori bizarr time approach wrote mainli sf wrote peopl truth religion rather technolog although often believ met sort god remain sceptic amongst novel follow relev galact pot healer fallibl alien deiti summon group earth craftsmen women remot planet rais giant cathedr beneath ocean deiti begin demand faith earther pot healer joe fernwright unabl compli polish iron amus novel maze death noteworthi descript technolog base religion vali schizophren hero search hidden mysteri gnostic christian realiti fire brain pink laser beam unknown possibl divin origin accompani dogmat dismiss atheist friend assort odd charact divin invas god invad earth make young woman pregnant return anoth star system unfortun termin ill must assist dead man whose brain wire 24 hour easi listen music margaret atwood handmaid tale stori base premis us congress mysteri assassin fundamentalist quickli take charg nation set right book diari woman life tri live new christian theocraci women right properti revok bank account close sin luxuri outlaw radio use read bibl crime punish retroact doctor perform legal abort old world hunt hang atwood write style difficult get use first tale grow chill goe variou author bibl somewhat dull rambl work often critic howev probabl worth read know fuss exist mani differ version make sure get one true version book non fiction peter de rosa vicar christ bantam press 1988 although de rosa seem christian even cathol enlight histori papal immor adulteri fallaci etc german translat gott erst diener die dunkl seit de papsttum droemer knaur 1989 michael martin atheism philosoph justif templ univers press philadelphia usa detail scholarli justif atheism contain outstand appendix defin terminolog usag necessarili tendenti area argu neg atheism e non belief exist god also posit atheism belief non exist god includ great refut challeng argument god particular attent paid refut contempori theist platinga swinburn 541 page isbn 0 87722 642 3 hardcov paperback also avail case christian templ univers press comprehens critiqu christian consid best contemporari defenc christian ultim demonstr unsupport incoher 273 page isbn 0 87722 767 5 jame turner without god without creed john hopkin univers press baltimor md usa subtitl origin unbelief america examin way unbelief whether agnost atheist becam mainstream altern world view focuss period 1770 1900 consid franc britain emphasi american particularli new england develop neither religi histori secular atheism without god without creed rather intellectu histori fate singl idea belief god exist 316 page isbn hardcov 0 8018 2494 x paper 0 8018 3407 4 georg seld editor great thought ballantin book new york usa dictionari quotat differ kind concentr statement write explicitli implicitli present person philosophi world view includ obscur often suppress opinion mani peopl popular observ trace way variou peopl express twist idea centuri quit number quotat deriv cardiff great men think religion noy view religion 490 page isbn paper 0 345 29887 x richard swinburn exist god revis edit clarendon paperback oxford book second volum trilog began coher theism 1977 conclud faith reason 1981 work swinburn attempt construct seri induct argument exist god argument somewhat tendenti reli upon imput late 20th centuri western christian valu aesthet god supposedli simpl conceiv decis reject macki miracl theism revis edit exist god swinburn includ appendix make somewhat incoher attempt rebut macki j l macki miracl theism oxford posthum volum contain comprehens review princip argument exist god rang classic philosoph posit descart anselm berkeley hume et al moral argument newman kant sidgwick recent restat classic these plantinga swinburn also address posit push concept god beyond realm ration kierkegaard kung philip well replac god leli axiarch book delight read less formalist better written martin work refreshingli direct compar hand wave swinburn jame haught holi horror illustr histori religi murder mad prometheu book look religi persecut ancient time present day christian librari congress catalog card number 89 64079 1990 norm r allen jr african american human antholog see list african american human gordon stein antholog atheism ration prometheu book antholog cover wide rang subject includ devil evil moral histori freethought comprehens bibliographi edmund cohen mind bibl believ prometheu book studi peopl becom christian fundamentalist effect net resourc small mail base archiv server manti co uk carri archiv old alt atheism moder articl assort file inform send mail archiv server manti co uk say help send atheism index mail back repli mathew ÿ ')\n"
     ]
    }
   ],
   "source": [
    "get_tf_idf(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
